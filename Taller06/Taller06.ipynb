{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457e40e5-9ec8-431d-ac21-7d91dfa14a7b",
   "metadata": {},
   "source": [
    "# Preparación del dataset \"Wikipedia Movie Plots\"\n",
    "\n",
    "## Nombre: Michael Pillaga\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7ff29-f732-41b2-b922-663643261757",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PARTE 1: RECUPERACION CON TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbaab7-ba28-4723-8274-982df173859e",
   "metadata": {},
   "source": [
    "### PASO 1: CARGAR LOS DATOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33addc0-d1c7-440e-a776-24c6e2bd984d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del dataset: Index(['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast',\n",
      "       'Genre', 'Wiki Page', 'Plot'],\n",
      "      dtype='object')\n",
      "   Release Year                             Title Origin/Ethnicity  \\\n",
      "0          1901            Kansas Saloon Smashers         American   \n",
      "1          1901     Love by the Light of the Moon         American   \n",
      "2          1901           The Martyred Presidents         American   \n",
      "3          1901  Terrible Teddy, the Grizzly King         American   \n",
      "4          1902            Jack and the Beanstalk         American   \n",
      "\n",
      "                             Director Cast    Genre  \\\n",
      "0                             Unknown  NaN  unknown   \n",
      "1                             Unknown  NaN  unknown   \n",
      "2                             Unknown  NaN  unknown   \n",
      "3                             Unknown  NaN  unknown   \n",
      "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
      "\n",
      "                                           Wiki Page  \\\n",
      "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
      "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
      "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
      "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
      "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar el dataset desde un archivo CSV\n",
    "# Asegúrate de que el archivo esté en la misma carpeta que tu notebook o ajusta la ruta\n",
    "file_path = \"./wiki_movie_plots_deduped.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verifica las columnas del dataset\n",
    "print(\"Columnas del dataset:\", df.columns)\n",
    "\n",
    "# Opcional: muestra algunas filas para asegurarte de que los datos están cargados correctamente\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4b359-7a8c-4ae4-831d-0f521e471c9b",
   "metadata": {},
   "source": [
    "### PASO 2: NORMALIZACION DEL TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874607a8-7cbd-4d01-a856-2c6272ab537f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "0            Kansas Saloon Smashers   \n",
      "1     Love by the Light of the Moon   \n",
      "2           The Martyred Presidents   \n",
      "3  Terrible Teddy, the Grizzly King   \n",
      "4            Jack and the Beanstalk   \n",
      "\n",
      "                                     Normalized_Plot  \n",
      "0  bartender working saloon, serving drink custom...  \n",
      "1  moon, painted smiling face hang park night. yo...  \n",
      "2  film, minute long, composed two shots. first, ...  \n",
      "3  lasting 61 second consisting two shots, first ...  \n",
      "4  earliest known adaptation classic fairytale, f...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Inicializar lematizador y stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para normalizar el texto\n",
    "def normalize_text(text):\n",
    "    # Convertir a minúsculas y tokenizar\n",
    "    tokens = text.lower().split()\n",
    "    # Eliminar stopwords y lematizar\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Reconstruir el texto normalizado\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar normalización al texto de las tramas\n",
    "df['Normalized_Plot'] = df['Plot'].apply(normalize_text)\n",
    "\n",
    "# Verificar los primeros resultados normalizados\n",
    "print(df[['Title', 'Normalized_Plot']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba3eed-8793-46da-b75c-51df1edca7b0",
   "metadata": {},
   "source": [
    "### PASO 3: CONFIGURAR TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5514acdf-9337-44aa-acf2-26adfcaee5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz TF-IDF generada con dimensiones: (34886, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Configurar el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Generar la matriz TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Normalized_Plot'])\n",
    "\n",
    "# Verificar las dimensiones de la matriz\n",
    "print(f\"Matriz TF-IDF generada con dimensiones: {tfidf_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bba6ec-13af-4301-b53b-86c04ad85099",
   "metadata": {},
   "source": [
    "### PASO 4: REALIZAR CONSULTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bdf692a-92d0-4e49-aa61-20f01d67d40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos recuperados con puntuaciones de similitud:\n",
      "                                Title  \\\n",
      "22892    The Thousand Faces of Dunjia   \n",
      "12568                    Theodore Rex   \n",
      "34882              Çalgı Çengi İkimiz   \n",
      "33715  Space Sheriff Gavan: The Movie   \n",
      "12103  We're Back! A Dinosaur's Story   \n",
      "\n",
      "                                                    Plot  Similarity_Score  \n",
      "22892  The film follows a group of swordsmen's advent...          0.382771  \n",
      "12568  In an alternate futuristic society where human...          0.373772  \n",
      "34882  Two musicians, Salih and Gürkan, described the...          0.353538  \n",
      "33715  Fulfilling their fifteen-year-old childhood dr...          0.337162  \n",
      "12103  In present-day New York City, an Eastern blueb...          0.329330  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Función para normalizar consultas\n",
    "def normalize_query(query):\n",
    "    tokens = query.lower().split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Función para evaluar los resultados con TF-IDF\n",
    "def evaluate_results(query, vectorizer, tfidf_matrix, top_n=5):\n",
    "    # Normalizar la consulta antes de vectorizarla\n",
    "    normalized_query = normalize_query(query)\n",
    "    # Vectorizar la consulta normalizada\n",
    "    query_vec = vectorizer.transform([normalized_query])\n",
    "    # Calcular similitud del coseno\n",
    "    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    # Obtener los índices de los documentos más similares\n",
    "    top_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    # Recuperar los documentos con sus puntuaciones\n",
    "    results = df.iloc[top_indices].copy()\n",
    "    results['Similarity_Score'] = cosine_similarities[top_indices]\n",
    "    return results[['Title', 'Plot', 'Similarity_Score']]\n",
    "\n",
    "# Realizar una consulta\n",
    "query = \"space adventure with dinosaurs\"  # Cambia esto por tu consulta\n",
    "evaluated_results = evaluate_results(query, vectorizer, tfidf_matrix)\n",
    "\n",
    "# Mostrar los resultados evaluados\n",
    "print(\"Documentos recuperados con puntuaciones de similitud:\")\n",
    "print(evaluated_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94666eb-f53b-41ab-a897-bc538f96a765",
   "metadata": {},
   "source": [
    "## PARTE 2: RECUPERACION CON BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e9408-fb32-4a62-9e0b-e1fa6e780389",
   "metadata": {},
   "source": [
    "### PASO 1: Verificar conexion con elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ec1317-ac2f-4cf9-8c5f-7ee2690a7614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa a Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Conexión al cliente Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Verificar si está conectado\n",
    "if es.ping():\n",
    "    print(\"Conexión exitosa a Elasticsearch\")\n",
    "else:\n",
    "    print(\"Error al conectar con Elasticsearch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55e075-bd36-4456-b35d-cda3e4400e73",
   "metadata": {},
   "source": [
    "### Verificar que el indice existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aef970e-b8f6-482e-a371-ba742ca9bdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices existentes:\n",
      "movies\n"
     ]
    }
   ],
   "source": [
    "# Listar los índices existentes con argumentos nombrados\n",
    "indices = es.indices.get_alias(index=\"*\")\n",
    "print(\"Índices existentes:\")\n",
    "for index_name in indices:\n",
    "    print(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73f68a-c1bc-4e1f-acf6-b6fef3a8962d",
   "metadata": {},
   "source": [
    "### PASO 2: Realizar consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bf5446f-4297-4ed4-862c-fd78e84d545d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos recuperados con BM25:\n",
      "Title:  Blinky Bill the Movie\n",
      "Plot: In the town of Greenpatch in Australia, a courageous young...\n",
      "BM25 Score: 16.69516\n",
      "--------------------------------------------------\n",
      "Title: Magic Tree House\n",
      "Plot: Jack is a shy but confident bookworm and his sister...\n",
      "BM25 Score: 14.60886\n",
      "--------------------------------------------------\n",
      "Title: Unknown Island\n",
      "Plot: Adventure-seeker Ted Osborne (Phillip Reed) and his fiancee Carole (Virginia...\n",
      "BM25 Score: 14.467151\n",
      "--------------------------------------------------\n",
      "Title: Robot Monster\n",
      "Plot: Evil Moon robot Ro-Man Extension XJ-2 (Barrows), referred to as...\n",
      "BM25 Score: 13.367545\n",
      "--------------------------------------------------\n",
      "Title: We're Back! A Dinosaur's Story\n",
      "Plot: In present-day New York City, an Eastern bluebird named Buster...\n",
      "BM25 Score: 13.172708\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saitama\\AppData\\Local\\Temp\\ipykernel_5412\\2212728940.py:11: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=index_name, body=body, size=size)\n"
     ]
    }
   ],
   "source": [
    "# Función para realizar consultas con BM25\n",
    "def search_query_bm25(query, index_name, size=5):\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title\", \"plot\"]  # Campos donde buscar\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index=index_name, body=body, size=size)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    results = []\n",
    "    for result in response[\"hits\"][\"hits\"]:\n",
    "        title = result['_source']['title']\n",
    "        plot = \" \".join(result['_source']['plot'].split()[:10])  # Limitar a 10 palabras del plot\n",
    "        score = result['_score']\n",
    "        results.append({\"Title\": title, \"Plot\": plot, \"BM25_Score\": score})\n",
    "    return results\n",
    "\n",
    "# Realizar una consulta con BM25\n",
    "query = \"space adventure with dinosaurs\"  # Cambia esto por tu consulta\n",
    "index_name = \"movies\"  # Nombre del índice en Elasticsearch\n",
    "bm25_results = search_query_bm25(query, index_name)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Documentos recuperados con BM25:\")\n",
    "for result in bm25_results:\n",
    "    print(f\"Title: {result['Title']}\")\n",
    "    print(f\"Plot: {result['Plot']}...\")\n",
    "    print(f\"BM25 Score: {result['BM25_Score']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1183b6-aab8-47a8-ab79-0d4c9136b7e9",
   "metadata": {},
   "source": [
    "### PASO 3: Evaluar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d7291e5-3c16-43b1-9e67-3ae56254e39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparación de Resultados ---\n",
      "\n",
      "Comparación 1:\n",
      "TF-IDF - Title: The Thousand Faces of Dunjia, Similarity Score: 0.3827709009592723\n",
      "TF-IDF - Plot: The film follows a group of swordsmen's adventures to secretly...\n",
      "BM25  - Title:  Blinky Bill the Movie, BM25 Score: 16.69516\n",
      "BM25  - Plot: In the town of Greenpatch in Australia, a courageous young...\n",
      "--------------------------------------------------\n",
      "\n",
      "Comparación 2:\n",
      "TF-IDF - Title: Theodore Rex, Similarity Score: 0.3737716024557386\n",
      "TF-IDF - Plot: In an alternate futuristic society where humans and anthropomorphic dinosaurs...\n",
      "BM25  - Title: Magic Tree House, BM25 Score: 14.60886\n",
      "BM25  - Plot: Jack is a shy but confident bookworm and his sister...\n",
      "--------------------------------------------------\n",
      "\n",
      "Comparación 3:\n",
      "TF-IDF - Title: Çalgı Çengi İkimiz, Similarity Score: 0.3535381884884966\n",
      "TF-IDF - Plot: Two musicians, Salih and Gürkan, described the adventures of their...\n",
      "BM25  - Title: Unknown Island, BM25 Score: 14.467151\n",
      "BM25  - Plot: Adventure-seeker Ted Osborne (Phillip Reed) and his fiancee Carole (Virginia...\n",
      "--------------------------------------------------\n",
      "\n",
      "Comparación 4:\n",
      "TF-IDF - Title: Space Sheriff Gavan: The Movie, Similarity Score: 0.3371617834432122\n",
      "TF-IDF - Plot: Fulfilling their fifteen-year-old childhood dream to venture into space, Geki...\n",
      "BM25  - Title: Robot Monster, BM25 Score: 13.367545\n",
      "BM25  - Plot: Evil Moon robot Ro-Man Extension XJ-2 (Barrows), referred to as...\n",
      "--------------------------------------------------\n",
      "\n",
      "Comparación 5:\n",
      "TF-IDF - Title: We're Back! A Dinosaur's Story, Similarity Score: 0.3293302214406445\n",
      "TF-IDF - Plot: In present-day New York City, an Eastern bluebird named Buster...\n",
      "BM25  - Title: We're Back! A Dinosaur's Story, BM25 Score: 13.172708\n",
      "BM25  - Plot: In present-day New York City, an Eastern bluebird named Buster...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Comparar los resultados de BM25 y TF-IDF\n",
    "def compare_bm25_tfidf(tfidf_results, bm25_results):\n",
    "    print(\"\\n--- Comparación de Resultados ---\")\n",
    "    for i, (tfidf, bm25) in enumerate(zip(tfidf_results.to_dict('records'), bm25_results)):\n",
    "        print(f\"\\nComparación {i + 1}:\")\n",
    "        print(f\"TF-IDF - Title: {tfidf['Title']}, Similarity Score: {tfidf['Similarity_Score']}\")\n",
    "        print(f\"TF-IDF - Plot: {' '.join(tfidf['Plot'].split()[:10])}...\")\n",
    "        print(f\"BM25  - Title: {bm25['Title']}, BM25 Score: {bm25['BM25_Score']}\")\n",
    "        print(f\"BM25  - Plot: {bm25['Plot']}...\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Llamar la función de comparación\n",
    "compare_bm25_tfidf(evaluated_results, bm25_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18303bc1-1e90-471f-b79b-fb9a3e4f7ed3",
   "metadata": {},
   "source": [
    "## PARTE 3: RECUPERACION CON FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe6ea6-9f63-4dd6-a15c-c90844a68a7d",
   "metadata": {},
   "source": [
    "### PASO 1: IMPORTAMOS LIBRERIAS Y CARGAMOS EL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b401f59-ef69-4d82-a2ce-2f2c0a201f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con las siguientes columnas:\n",
      "   Release Year                             Title Origin/Ethnicity  \\\n",
      "0          1901            Kansas Saloon Smashers         American   \n",
      "1          1901     Love by the Light of the Moon         American   \n",
      "2          1901           The Martyred Presidents         American   \n",
      "3          1901  Terrible Teddy, the Grizzly King         American   \n",
      "4          1902            Jack and the Beanstalk         American   \n",
      "\n",
      "                             Director Cast    Genre  \\\n",
      "0                             Unknown  NaN  unknown   \n",
      "1                             Unknown  NaN  unknown   \n",
      "2                             Unknown  NaN  unknown   \n",
      "3                             Unknown  NaN  unknown   \n",
      "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
      "\n",
      "                                           Wiki Page  \\\n",
      "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
      "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
      "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
      "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
      "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = \"./wiki_movie_plots_deduped.csv\"  # Cambia esto por la ruta del archivo\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(\"Dataset cargado con las siguientes columnas:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bedb9-8606-42df-ae04-d7058fcae4e7",
   "metadata": {},
   "source": [
    "### Verificamos dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86eb045f-9736-4ab9-90a6-ba44000dd7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2\n",
      "Torchvision version: 0.17.2\n",
      "Sentence-Transformers importado correctamente\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(\"Sentence-Transformers importado correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe209f6-ca1a-47c3-ad24-6cc0c22f09ab",
   "metadata": {},
   "source": [
    "### Cargamos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16dad484-d0c9-455e-9a02-321661840c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con las siguientes columnas:\n",
      "   Release Year                             Title Origin/Ethnicity  \\\n",
      "0          1901            Kansas Saloon Smashers         American   \n",
      "1          1901     Love by the Light of the Moon         American   \n",
      "2          1901           The Martyred Presidents         American   \n",
      "3          1901  Terrible Teddy, the Grizzly King         American   \n",
      "4          1902            Jack and the Beanstalk         American   \n",
      "\n",
      "                             Director Cast    Genre  \\\n",
      "0                             Unknown  NaN  unknown   \n",
      "1                             Unknown  NaN  unknown   \n",
      "2                             Unknown  NaN  unknown   \n",
      "3                             Unknown  NaN  unknown   \n",
      "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
      "\n",
      "                                           Wiki Page  \\\n",
      "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
      "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
      "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
      "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
      "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = \"./wiki_movie_plots_deduped.csv\"  # Cambia esto por la ruta de tu archivo\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verificar las primeras filas del dataset\n",
    "print(\"Dataset cargado con las siguientes columnas:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d5f6e-baa5-4844-9eb3-2c9add7e5628",
   "metadata": {},
   "source": [
    "### PASO 1: NORMALIZAR TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23f3d4a8-f73f-4535-9ff3-149eb2a57e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "0            Kansas Saloon Smashers   \n",
      "1     Love by the Light of the Moon   \n",
      "2           The Martyred Presidents   \n",
      "3  Terrible Teddy, the Grizzly King   \n",
      "4            Jack and the Beanstalk   \n",
      "\n",
      "                                     Normalized_Plot  \n",
      "0  bartender working saloon, serving drink custom...  \n",
      "1  moon, painted smiling face hang park night. yo...  \n",
      "2  film, minute long, composed two shots. first, ...  \n",
      "3  lasting 61 second consisting two shots, first ...  \n",
      "4  earliest known adaptation classic fairytale, f...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Inicializar lematizador y stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para normalizar el texto\n",
    "def normalize_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar normalización al texto de las tramas\n",
    "df['Normalized_Plot'] = df['Plot'].apply(normalize_text)\n",
    "\n",
    "# Verificar los primeros resultados normalizados\n",
    "print(df[['Title', 'Normalized_Plot']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389a189-49df-49d3-a70f-dd8fbbe57f76",
   "metadata": {},
   "source": [
    "### PASO 2: GENERAR EMBEDDINGS CON SENTENCETRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fb8d6c0-2bc9-40d7-a92c-60ef5fa8ce09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c78db8cc9c343e4beb4f73dd88aad7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\InstallApps2023\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Saitama\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7062563a915d418dbfb20a7c93b2531c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647b15103934485580d9a31b551d6f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767f175abcab4f90b364b1c92daa1bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8137419d4c047c9a4ff0e10f6a87af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dbff6fb5b543e9be5155fde037d6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36dd8e31f8a4ba487f981fcd9730730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f32ca06f1944a78c6ca4ebf37a3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a583aa303a4c39820b44bbbd8f0e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8e08ac0fed44e18f6573d3099d675c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8d03bb8eaa418ab7a698fd8f36c1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c29953ddaa43a2a2fe6b877f673b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generados con dimensiones: (34886, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo preentrenado\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Puedes cambiar el modelo si prefieres\n",
    "\n",
    "# Generar embeddings para las tramas normalizadas\n",
    "embeddings = model.encode(df['Normalized_Plot'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Verificar las dimensiones de los embeddings\n",
    "print(f\"Embeddings generados con dimensiones: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013a8c8-75d3-4303-b07a-064c39d7f0ca",
   "metadata": {},
   "source": [
    "### PASO 3: CREAR EL INDICE FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b361eac5-a86d-4e6e-beea-8eca060c3c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de vectores en el índice: 34886\n"
     ]
    }
   ],
   "source": [
    "# Crear el índice FAISS\n",
    "import faiss\n",
    "\n",
    "dimension = embeddings.shape[1]  # Dimensión de los embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 = Distancia Euclidiana\n",
    "\n",
    "# Agregar los embeddings al índice\n",
    "index.add(embeddings)\n",
    "\n",
    "# Verificar cuántos vectores hay en el índice\n",
    "print(f\"Cantidad de vectores en el índice: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ae031-d9ed-4f09-ad1c-d0f5780f6670",
   "metadata": {},
   "source": [
    "### PASO 4: REALIZAR CONSULTAS CON FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "013a9aa4-237e-4b4f-820c-d488450b7294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos recuperados con FAISS:\n",
      "Title: Dinosaurus!\n",
      "Plot: The movie is about American men building a harbour on...\n",
      "Distance: 0.9749438166618347\n",
      "--------------------------------------------------\n",
      "Title: Dinosaurs! – A Fun-Filled Trip Back in Time!\n",
      "Plot: The video—with beginning scenes filmed in 1987—begins with a young...\n",
      "Distance: 0.9765295386314392\n",
      "--------------------------------------------------\n",
      "Title: We're Back! A Dinosaur's Story\n",
      "Plot: In present-day New York City, an Eastern bluebird named Buster...\n",
      "Distance: 0.9784306287765503\n",
      "--------------------------------------------------\n",
      "Title: Yona Yona Penguin\n",
      "Plot: An animated adventure about three children who travel to a...\n",
      "Distance: 1.007900595664978\n",
      "--------------------------------------------------\n",
      "Title: Jurassic Park III\n",
      "Plot: Ben Hildebrand and 12-year-old Eric Kirby go parasailing around the...\n",
      "Distance: 1.0250296592712402\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Función para realizar consultas con FAISS\n",
    "def search_faiss(query, model, index, top_n=5):\n",
    "    # Generar embedding de la consulta\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    # Buscar en el índice FAISS\n",
    "    distances, indices = index.search(query_embedding, top_n)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    results = []\n",
    "    for idx, distance in zip(indices[0], distances[0]):\n",
    "        title = df.iloc[idx]['Title']\n",
    "        plot = \" \".join(df.iloc[idx]['Plot'].split()[:10])  # Limitar a 10 palabras\n",
    "        results.append({\"Title\": title, \"Plot\": plot, \"Distance\": distance})\n",
    "    return results\n",
    "\n",
    "# Realizar una consulta\n",
    "query = \"space adventure with dinosaurs\"  # Cambia esto por tu consulta\n",
    "faiss_results = search_faiss(query, model, index)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Documentos recuperados con FAISS:\")\n",
    "for result in faiss_results:\n",
    "    print(f\"Title: {result['Title']}\")\n",
    "    print(f\"Plot: {result['Plot']}...\")\n",
    "    print(f\"Distance: {result['Distance']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d610b-fd01-483c-8269-bee751203721",
   "metadata": {},
   "source": [
    "### PASO 5: COMPARAMOS RESULTADOS CON TF-IDF Y BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f67e43-e0ff-4464-a876-f8c0f32eece6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluated_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Comparar resultados\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m compare_all_results(evaluated_results, bm25_results, faiss_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluated_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Comparar resultados de FAISS con TF-IDF y BM25\n",
    "def compare_all_results(tfidf_results, bm25_results, faiss_results):\n",
    "    print(\"\\n--- Comparación de Resultados ---\")\n",
    "    for i, (tfidf, bm25, faiss) in enumerate(zip(tfidf_results.to_dict('records'), bm25_results, faiss_results)):\n",
    "        print(f\"\\nComparación {i + 1}:\")\n",
    "        print(f\"TF-IDF - Title: {tfidf['Title']}, Similarity Score: {tfidf['Similarity_Score']}\")\n",
    "        print(f\"BM25  - Title: {bm25['Title']}, BM25 Score: {bm25['BM25_Score']}\")\n",
    "        print(f\"FAISS - Title: {faiss['Title']}, Distance: {faiss['Distance']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Comparar resultados\n",
    "compare_all_results(evaluated_results, bm25_results, faiss_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc2732-9969-4b20-a3f1-8764fd4973ed",
   "metadata": {},
   "source": [
    "## PARTE 4: RECUPERACION CON CHROMADB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b5eb5-3a9e-46bb-84e8-ba7e43d5d597",
   "metadata": {},
   "source": [
    "### PASO 1: CONFIGURAR CHROMADB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b0987a-4259-46da-bbab-f44754319771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando ChromaDB...\n",
      "Listando colecciones existentes...\n",
      "Colecciones existentes: []\n",
      "Se creó una nueva colección: movies\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Configuración de la base de datos ChromaDB con la nueva arquitectura\n",
    "print(\"Configurando ChromaDB...\")\n",
    "chroma_client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_db\",  # Directorio donde se guardará la base de datos\n",
    "    anonymized_telemetry=False  # Desactiva telemetría si lo prefieres\n",
    "))\n",
    "\n",
    "# Listar colecciones existentes\n",
    "print(\"Listando colecciones existentes...\")\n",
    "existing_collections = [col.name for col in chroma_client.list_collections()]\n",
    "print(\"Colecciones existentes:\", existing_collections)\n",
    "\n",
    "# Verificar si la colección 'movies' ya existe\n",
    "collection_name = \"movies\"\n",
    "if collection_name in existing_collections:\n",
    "    # Cargar colección existente\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    print(f\"La colección '{collection_name}' ya existe con {collection.count()} documentos.\")\n",
    "else:\n",
    "    # Crear nueva colección\n",
    "    collection = chroma_client.create_collection(name=collection_name)\n",
    "    print(f\"Se creó una nueva colección: {collection_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470c650-fab1-40f5-9162-99a32c7b2d50",
   "metadata": {},
   "source": [
    "### PASO 2: INSERTAR DOCUMENTOS Y EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938324af-96b4-4fbd-ba4c-893a42663f61",
   "metadata": {},
   "source": [
    "### Cargamos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f725771e-6306-4f57-bbbb-bc52b93c4365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con 34886 registros y columnas: ['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast', 'Genre', 'Wiki Page', 'Plot']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = \"./wiki_movie_plots_deduped.csv\"  # Cambia esto por la ruta de tu archivo\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset cargado con {df.shape[0]} registros y columnas: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7d12bd-ce93-40e5-b50a-a2819c334bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intentando cargar embeddings y metadatos guardados...\n",
      "No se encontraron archivos guardados. Generando embeddings nuevos...\n",
      "Generando embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e09a9fd6c264c1f93a19e4abb8916ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generados y guardados correctamente. Dimensiones: (34886, 384)\n",
      "Listos para usar. Dimensiones de los embeddings: (34886, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Ruta para guardar los embeddings y metadatos\n",
    "EMBEDDINGS_FILE = \"embeddings.npy\"\n",
    "METADATA_FILE = \"metadata.pkl\"\n",
    "\n",
    "try:\n",
    "    # Intentar cargar los embeddings y metadatos si ya existen\n",
    "    print(\"Intentando cargar embeddings y metadatos guardados...\")\n",
    "    embeddings = np.load(EMBEDDINGS_FILE)\n",
    "    with open(METADATA_FILE, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    titles = metadata[\"titles\"]\n",
    "    plots = metadata[\"plots\"]\n",
    "    print(\"Embeddings y metadatos cargados correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    # Si los archivos no existen, generar los embeddings\n",
    "    print(\"No se encontraron archivos guardados. Generando embeddings nuevos...\")\n",
    "    # Cargar modelo más pequeño\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "\n",
    "    # Generar embeddings\n",
    "    print(\"Generando embeddings...\")\n",
    "    embeddings = model.encode(df['Plot'].tolist(), show_progress_bar=True)\n",
    "\n",
    "    # Guardar embeddings y metadatos\n",
    "    titles = df['Title'].tolist()\n",
    "    plots = df['Plot'].tolist()\n",
    "    np.save(EMBEDDINGS_FILE, embeddings)\n",
    "    with open(METADATA_FILE, \"wb\") as f:\n",
    "        pickle.dump({\"titles\": titles, \"plots\": plots}, f)\n",
    "\n",
    "    print(f\"Embeddings generados y guardados correctamente. Dimensiones: {embeddings.shape}\")\n",
    "\n",
    "# Embeddings y metadatos están listos para usarse\n",
    "print(f\"Listos para usar. Dimensiones de los embeddings: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e646cd14-eada-42b4-85fb-71f637e2111c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings y metadatos cargados correctamente.\n",
      "Dimensiones de los embeddings: (34886, 384)\n"
     ]
    }
   ],
   "source": [
    "# Definir las rutas para los archivos\n",
    "EMBEDDINGS_FILE = \"embeddings.npy\"\n",
    "METADATA_FILE = \"metadata.pkl\"\n",
    "\n",
    "# Importar las librerías necesarias\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    # Intentar cargar los embeddings y metadatos\n",
    "    embeddings = np.load(EMBEDDINGS_FILE)\n",
    "    with open(METADATA_FILE, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    titles = metadata[\"titles\"]\n",
    "    plots = metadata[\"plots\"]\n",
    "    print(\"Embeddings y metadatos cargados correctamente.\")\n",
    "    print(f\"Dimensiones de los embeddings: {embeddings.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Los archivos de embeddings o metadatos no están disponibles. Necesitas generarlos nuevamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03295a11-ddc9-4254-9209-f13d5e3cb620",
   "metadata": {},
   "source": [
    "### Paso 3: Insertar Documentos y Embeddings en ChromaDB python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e917825-4fdc-4b77-8ed7-5acd432fd757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurar el tamaño del lote\n",
    "batch_size = 1000  # Ajusta este valor según los recursos disponibles\n",
    "\n",
    "try:\n",
    "    # Dividir los documentos y embeddings en lotes para la inserción\n",
    "    for i in range(0, len(plots), batch_size):\n",
    "        # Crear el lote actual\n",
    "        batch_documents = plots[i:i + batch_size]\n",
    "        batch_embeddings = embeddings[i:i + batch_size]\n",
    "        batch_ids = [str(j) for j in range(i, i + len(batch_documents))]\n",
    "        batch_metadatas = [{\"title\": titles[j]} for j in range(i, i + len(batch_documents))]\n",
    "\n",
    "        # Insertar el lote en la colección\n",
    "        collection.add(\n",
    "            embeddings=batch_embeddings,\n",
    "            documents=batch_documents,\n",
    "            metadatas=batch_metadatas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "        print(f\"Se insertó el lote {i // batch_size + 1} con {len(batch_documents)} documentos.\")\n",
    "\n",
    "    # Verificar el número total de documentos en la colección\n",
    "    print(f\"Cantidad total de documentos en la colección '{collection_name}': {collection.count()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error durante la inserción: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcfca24-efe7-4649-b26a-99d62147d0f2",
   "metadata": {},
   "source": [
    "### Paso 4: Realizar Consultas con ChromaDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f81f02-e352-4dd5-b053-bda741fb463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar consultas\n",
    "def query_chromadb(query_text, model, collection, top_n=5):\n",
    "    # Generar el embedding de la consulta\n",
    "    query_embedding = model.encode([query_text])\n",
    "\n",
    "    # Realizar la consulta en la colección\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=top_n\n",
    "    )\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f\"Resultados para la consulta: '{query_text}'\")\n",
    "    for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "        print(f\"\\nResultado {i+1}:\")\n",
    "        print(f\"Título: {metadata['title']}\")\n",
    "        print(f\"Trama: {doc}\")\n",
    "\n",
    "# Ejemplo de consulta\n",
    "query_text = \"space adventure with dinosaurs\"\n",
    "query_chromadb(query_text, model, collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c712221-f9a9-4e85-8e4c-f4102c1807a6",
   "metadata": {},
   "source": [
    "## Parte 5: Comparacion de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e39f77-1665-4fb9-93e5-941284b8aa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_results(faiss_results, tfidf_results, bm25_results, chromadb_results):\n",
    "    print(\"\\n--- Comparación de Resultados ---\")\n",
    "    max_results = max(len(faiss_results), len(tfidf_results), len(bm25_results), len(chromadb_results))\n",
    "    \n",
    "    for i in range(max_results):\n",
    "        print(f\"\\nComparación {i + 1}:\")\n",
    "        if i < len(faiss_results):\n",
    "            print(f\"FAISS    - Title: {faiss_results[i]['Title']}, Distance: {faiss_results[i]['Distance']:.4f}\")\n",
    "        else:\n",
    "            print(\"FAISS    - Sin resultado\")\n",
    "\n",
    "        if i < len(tfidf_results):\n",
    "            print(f\"TF-IDF   - Title: {tfidf_results[i]['Title']}, Similarity: {tfidf_results[i]['Similarity_Score']:.4f}\")\n",
    "        else:\n",
    "            print(\"TF-IDF   - Sin resultado\")\n",
    "\n",
    "        if i < len(bm25_results):\n",
    "            print(f\"BM25     - Title: {bm25_results[i]['Title']}, Score: {bm25_results[i]['BM25_Score']:.4f}\")\n",
    "        else:\n",
    "            print(\"BM25     - Sin resultado\")\n",
    "\n",
    "        if i < len(chromadb_results):\n",
    "            print(f\"ChromaDB - Title: {chromadb_results[i]['Title']}, Distance: {chromadb_results[i]['Distance']:.4f}\")\n",
    "        else:\n",
    "            print(\"ChromaDB - Sin resultado\")\n",
    "\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c71d7-c854-4a10-b4a2-1f1447281d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bddc62-0b35-42b2-970c-95bda9227008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c33a95-b48b-4ecb-a953-1b3e85417b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce275e5-7bfa-4fa6-9740-0e38c4c59282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3c641-e0be-4205-b4b2-06f7a97b9616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8d8c3-e9d7-4598-9fc7-55d20fe63ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
