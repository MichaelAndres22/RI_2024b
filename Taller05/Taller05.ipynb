{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4804ef-f7cf-48d9-b6e6-b5140ec5c94e",
   "metadata": {},
   "source": [
    "## Taller 05: Herramientas para Indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa48d3f-49c9-437d-bd8c-51b426f07f1a",
   "metadata": {},
   "source": [
    "Integrantes: Michael Pillaga, Alexis Vera, Jordy Quishpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c0f76-edc5-400a-8bd6-6d4b538555dc",
   "metadata": {},
   "source": [
    "### Preprocesamiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a81ba93-4172-442d-b0ed-c0916900953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Saitama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "# Descargar los recursos necesarios de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152f999-4f7e-48d8-83a0-d3741526473f",
   "metadata": {},
   "source": [
    "### Normalizacion de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303592b4-f792-48af-a217-d013b9848f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "file_path = './wiki_movie_plots_deduped.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inicializar el lematizador y stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para normalizar el texto\n",
    "def normalize_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación y caracteres especiales\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenizar\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords y lematizar las palabras\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Aplicar la normalización a las tramas de las películas\n",
    "df['Normalized_Plot'] = df['Plot'].apply(normalize_text)\n",
    "\n",
    "# Crear el índice invertido\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    title = row['Title']\n",
    "    for word in row['Normalized_Plot']:\n",
    "        inverted_index[word].add(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92926341-0dd2-496f-b4ce-10a175a7c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 películas que contienen la palabra 'cyborg':\n",
      "['Future War', 'The Time Guardian', 'Kamen Rider the First', '964 Pinocchio', 'Godzilla: Tokyo S.O.S.']\n"
     ]
    }
   ],
   "source": [
    "# Consultar el índice invertido para la palabra 'cyborg'\n",
    "word = 'cyborg'  # Palabra que quieres buscar\n",
    "movies_with_word = inverted_index[word] if word in inverted_index else set()\n",
    "\n",
    "# Mostrar solo las primeras 5 películas\n",
    "print(f\"Primeras 5 películas que contienen la palabra '{word}':\")\n",
    "print(list(movies_with_word)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089a113-749a-4326-9adb-949ff4aff5ae",
   "metadata": {},
   "source": [
    "###  PARTE 2: Usar Whoosh para Indexacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bb4e29-6286-4f60-a01c-a777d7a49572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whoosh\n",
      "  Obtaining dependency information for whoosh from https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/468.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/468.8 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/468.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/468.8 kB 435.7 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 143.4/468.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  460.8/468.8 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 468.8/468.8 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: whoosh\n",
      "Successfully installed whoosh-2.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install whoosh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0530f74c-10e7-4d7a-8eca-8ebe166b9f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas relacionadas con 'cyborg':\n",
      "Title: Cyborg 3: The Recycler\n",
      "Plot: set desolate post apocalyptic world thriving golden age man cyborg ended cyborg hunted part cash haje female cyborg learns doc edford margaret avery somehow pregnant search fabled city cytown find eva...\n",
      "----------------------------------------\n",
      "Title: Cyborg Cop II\n",
      "Plot: crime bos jesse starkraven lead gang attack drug den cooperating starkravens demand assault quickly turn hostage situation police arrive renegade dea agent jack ryan arrives attempt negotiate starkrav...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009: Monster War\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009: Legend of the Super Galaxy\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = './wiki_movie_plots_deduped.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inicializar el lematizador y stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para normalizar el texto\n",
    "def normalize_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación y caracteres especiales\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenizar\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords y lematizar las palabras\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Aplicar la normalización a las tramas de las películas\n",
    "df['Normalized_Plot'] = df['Plot'].apply(normalize_text)\n",
    "\n",
    "# Definir el esquema del índice con los campos 'Title' y 'Plot'\n",
    "schema = Schema(\n",
    "    title=TEXT(stored=True),  # Título de la película\n",
    "    plot=TEXT(stored=True)    # Trama de la película\n",
    ")\n",
    "\n",
    "# Directorio donde se guardará el índice\n",
    "index_dir = 'movie_index'\n",
    "\n",
    "# Verificar si ya existe un índice en el directorio. Si no, crearlo\n",
    "if not os.path.exists(index_dir):\n",
    "    os.mkdir(index_dir)\n",
    "    ix = create_in(index_dir, schema)\n",
    "else:\n",
    "    ix = open_dir(index_dir)\n",
    "\n",
    "# Función para agregar películas al índice\n",
    "def add_movies_to_index(movies):\n",
    "    writer = ix.writer()  # Crear el escritor para agregar documentos\n",
    "    \n",
    "    for idx, row in movies.iterrows():\n",
    "        title = row['Title']\n",
    "        plot = row['Normalized_Plot']  # Usamos la trama normalizada\n",
    "        \n",
    "        # Convertir la lista de palabras de la trama de nuevo a una cadena\n",
    "        plot_text = \" \".join(plot)\n",
    "        \n",
    "        # Agregar cada película como documento en el índice\n",
    "        writer.add_document(title=title, plot=plot_text)\n",
    "    \n",
    "    # Guardar los documentos en el índice\n",
    "    writer.commit()\n",
    "\n",
    "# Agregar todas las películas al índice\n",
    "add_movies_to_index(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18ead7-0368-46b6-aca8-0192704df5bb",
   "metadata": {},
   "source": [
    "### Consulta usando Woosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dc1b5e-77a6-42ac-b8be-c49e865b4c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas relacionadas con 'cyborg':\n",
      "Title: Cyborg 3: The Recycler\n",
      "Plot: set desolate post apocalyptic world thriving golden age man cyborg ended cyborg hunted part cash haje female cyborg learns doc edford margaret avery somehow pregnant search fabled city cytown find eva...\n",
      "----------------------------------------\n",
      "Title: Cyborg Cop II\n",
      "Plot: crime bos jesse starkraven lead gang attack drug den cooperating starkravens demand assault quickly turn hostage situation police arrive renegade dea agent jack ryan arrives attempt negotiate starkrav...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009: Monster War\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n",
      "Title: Cyborg 009: Legend of the Super Galaxy\n",
      "Plot: nine people around world kidnapped evil black ghost organization undergo experiment turn cyborg superhuman power nine cyborg band together order stop black ghost achieving goal starting next world war...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Realizar una consulta en el índice\n",
    "query_string = \"cyborg\"  # Palabra clave para la consulta\n",
    "\n",
    "with ix.searcher() as searcher:\n",
    "    query = QueryParser(\"plot\", ix.schema).parse(query_string)\n",
    "    \n",
    "    # Ejecutar la búsqueda\n",
    "    results = searcher.search(query, limit=5)  # Limitamos a 5 resultados\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    print(f\"Películas relacionadas con '{query_string}':\")\n",
    "    for result in results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"Plot: {result['plot'][:200]}...\")  # Mostrar solo una parte de la trama\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95a122-43ad-4f46-b05d-8836e2485820",
   "metadata": {},
   "source": [
    "### PARTE 3: Elasticsearch para Indexación y Recuperación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05f8703-47c1-476c-a1bd-b5800bf9d540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Obtaining dependency information for elasticsearch from https://files.pythonhosted.org/packages/1e/82/832ff4bdb53429af0025f5032c8b4f3ba18915e08ce16fc55aa09e900e26/elasticsearch-8.17.0-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch-8.17.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch)\n",
      "  Obtaining dependency information for elastic-transport<9,>=8.15.1 from https://files.pythonhosted.org/packages/2a/0d/2dd25c06078070973164b661e0d79868e434998391f9aed74d4070aab270/elastic_transport-8.17.0-py3-none-any.whl.metadata\n",
      "  Downloading elastic_transport-8.17.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in e:\\installapps2023\\anaconda\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in e:\\installapps2023\\anaconda\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
      "Downloading elasticsearch-8.17.0-py3-none-any.whl (571 kB)\n",
      "   ---------------------------------------- 0.0/571.2 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 143.4/571.2 kB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 419.8/571.2 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  563.2/571.2 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  563.2/571.2 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  563.2/571.2 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 571.2/571.2 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading elastic_transport-8.17.0-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 61.4/64.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 61.4/64.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 61.4/64.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.5/64.5 kB 387.7 kB/s eta 0:00:00\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.17.0 elasticsearch-8.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a4ef2-8809-4854-98c0-8542f6c6ebaf",
   "metadata": {},
   "source": [
    "#### Conexion con Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c439174-8f94-4614-81c6-435befaad572",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para la conexion con Docker usamos los siguientes comandos desde la cmd:\n",
    "\n",
    "docker network create elastic\n",
    "\n",
    "docker pull docker.elastic.co/elasticsearch/elasticsearch:8.17.0\n",
    "\n",
    "docker run -d --name elasticsearch -p 9200:9200 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.17.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385ea934-1356-4207-92f4-e50e2cf91715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa a Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Conexión al cliente Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Verificar si está conectado\n",
    "if es.ping():\n",
    "    print(\"Conexión exitosa a Elasticsearch\")\n",
    "else:\n",
    "    print(\"Error al conectar con Elasticsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ba1261-676c-43fa-b3f5-8818d1c812c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice 'movies' creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Crear un índice con campos 'Title' y 'Plot'\n",
    "index_name = \"movies\"  # Nombre del índice\n",
    "\n",
    "# Definir el esquema del índice\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},  # Campo de texto completo\n",
    "            \"plot\": {\"type\": \"text\"}    # Campo de texto completo\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear el índice si no existe\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Índice '{index_name}' creado con éxito.\")\n",
    "else:\n",
    "    print(f\"El índice '{index_name}' ya existe.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98136ff3-5f2e-4a9d-940d-95facf5a30d3",
   "metadata": {},
   "source": [
    "#### Paso 2: Indexar documentos (películas)\n",
    "Supongamos que tienes un DataFrame df con las columnas Title y Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ee1635-6deb-493f-bbea-b87acbb33e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las 34886 películas fueron indexadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Indexar documentos en Elasticsearch\n",
    "def index_documents(es, index_name, df):\n",
    "    for idx, row in df.iterrows():\n",
    "        # Crear un documento con los campos Title y Plot\n",
    "        doc = {\n",
    "            \"title\": row['Title'],\n",
    "            \"plot\": row['Plot']\n",
    "        }\n",
    "        \n",
    "        # Usar el título como identificador único\n",
    "        es.index(index=index_name, id=idx+1, body=doc)\n",
    "    \n",
    "    # Mostrar mensaje una vez que todos los documentos se hayan indexado\n",
    "    print(f\"Todas las {len(df)} películas fueron indexadas correctamente.\")\n",
    "\n",
    "# Llamar a la función para indexar documentos\n",
    "index_documents(es, index_name, df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f1948-cec5-408e-929c-984168d17151",
   "metadata": {},
   "source": [
    "### Realizar Consultas\n",
    "Elasticsearch permite realizar búsquedas avanzadas utilizando el campo plot para buscar términos específicos como \"time travel\" o \"genetic engineering\". A continuación, te muestro cómo hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285c9db1-45a6-4b71-9698-b26ae6b5d66f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saitama\\AppData\\Local\\Temp\\ipykernel_14112\\1831387768.py:11: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(index=index_name, body=query, size=5)  # Limitar a 5 resultados\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas relacionadas con 'time travel':\n",
      "Título: Time Chasers\n",
      "Trama: Physics teacher and amateur pilot Nick Miller (Matthew Bruch) has finally completed his quest of enabling time travel, via a Commodore 64 and his small airplane. After being inspired by a television commercial for GenCorp, he uses a ruse to bring out both a GenCorp executive and a reporter from a local paper. To Nick's surprise, the reporter is Lisa Hansen (Bonnie Pritchard), an old high school flame. One trip to 2041 later and Gencorp's executive, Matthew Paul (Peter Harrington), quickly arranges Nick a meeting with CEO J.K. Robertson (George Woodard). Impressed by the potential of time travel, Robertson offers Nick a licensing agreement on the technology.\n",
      "The following week, Nick and Lisa meet at the supermarket and go on a date to the 1950s. However, another trip to 2041 reveals that GenCorp abused Nick's time travel technology, creating a dystopian future. In an attempt to tell J.K. about how GenCorp inadvertently ruined the future. J.K. dismisses the eventuality, and states that there's enough time to worry about how to fix it before it happens. J.K. sees Nick as a threat to GenCorp, and due to the association with the U.S. Government, considers Nick's actions as treason. Nick and Lisa escape GenCorp and spend the remainder of the film trying to reverse the damage to the future. When J.K. finds out about this, he and Matt try to shoot down Nick's plane, killing Lisa in the process while Nick jumps out before the plane crashes. This ultimately culminates in a fight in 1777 during the American Revolution, the deaths of the present Nick and Robertson, and the destruction of the time machine before the original demo, thus ensuring that the majority of the film's events never happen in the first place. The film ends with the now current Nick (now aware of the danger of his time machine) sabotaging his demonstration, and doing a pitch of how an elderly skydiver would be a better ad campaign for J.K.'s company. Furious about being misled, J.K. fires Matt. Nick deletes the eight 5¼\" floppy disks that make time travel possible. At the end of the film, Nick talks to Lisa in the supermarket as he did in the previous timeline.\n",
      "----------------------------------------\n",
      "Título: Love Story 2050\n",
      "Trama: Karan Malhotra (Harman Baweja) is a spirited and happy-go-lucky boy who does not follow the rules. Sana (Priyanka Chopra) is the opposite of Karan: a sweet and shy girl who lives life by the rules. Even though they are completely opposite, they fall in love, leading to a magical love story.[9]\n",
      "A scientist, Dr. Yatinder Khanna (Boman Irani), has dedicated 15 years of his life to building a time machine. Sana expresses a wish to time-travel to Mumbai in the year 2050, but she is killed in an accident before her marriage to Karan. Karan wishes to travel back in time and find Sana. Dr. Yatinder, Karan, and Sana's siblings, Rahul and Thea, travel forward in time and reach Mumbai in 2050. They are fascinated by the futuristic Mumbai, with its flying cars, holograms, robots, 200-story buildings and more.\n",
      "Twists and turns lead to the introduction of Ziesha (Priyanka Chopra), the reincarnation of Sana. Ziesha is a popular singer in 2050 who does not remember her past life, but gets flashbacks of it after meeting Karan. Unlike Sana, Ziesha is an arrogant, headstrong and rebellious girl who does not believe in love. She leads a lonely life after the death of her parents, which has embittered her.\n",
      "Karan and the others find themselves under the threat of the demi-god, Dr. Hoshi. After Karan tells Ziesha he loves her, he is taken away from her by the guards. Ziesha does not believe him when he tells her about his time travel. However, after reading Sana's diary, Ziesha ultimately remembers her past life. Karan returns to her and she declares her love for him and tells him she is Sana. Dr. Hoshi tries to capture Karan because he wants the time machine. After a wild attempt to catch Karan and Ziesha, Hoshi crashes into a nuclear substance truck and dies. Karan goes back to 2008 in the time machine with Ziesha and the rest of his family. Everyone is overjoyed to see their beloved Sana again and Karan proposes to her.[9][10]\n",
      "----------------------------------------\n",
      "Título: Timeranger vs. GoGoV\n",
      "Trama: In the 30th century, time travel becomes illegal after a time paradox crisis. The Time Protection Department (TPD) is established to watch for and stop time crimes. Four new enlistee cadets of the TPD are tricked by Don Dolnero and his gang into letting them time-travel to the year 2000 to commit various crimes and, to protect history, the four cadets pursue them. They encounter a severe problem: the Timeranger program requires five members for the first operation. They force a present-day martial artist, Tatsuya Asami, to join them, and they become the Timerangers. Tatsuya rents a building for them to live in, and they start a small odd-jobs business called Tomorrow Research to financially support themselves.\n",
      "Over time, the four cadets begin to realize that their presence would inevitably change the future in the form of the City Guardians, a security force under the employment of the Asami Corporation to protect the city from the Londers. The City Guardians form a tenuous relationship with the Timerangers, especially when Tatsuya's college acquaintance Naoto becomes Time Fire and later also becomes the City Guardian's captain.\n",
      "----------------------------------------\n",
      "Título: Abby Sen\n",
      "Trama: Kolkata 2013. Abby Sen is a 30-year-old television producer. He is academically brilliant, has a strong background in science and watching science fiction films is his greatest passion. But his programmes on television are never popular and fail to make a mark on the TRP ratings. And that is perhaps the only reason why Abby has lost no less than seven jobs. Every time he is fired, his wife Somy gets hysterical and throws down everything that she could lay her hands on. So Abby has not disclosed his last dismissal to her.\n",
      "By sheer coincidence, Abby meets a self-styled scientist who claims to have discovered a time-travel capsule. The scientist volunteers to take Abby back in time when getting a job was not that difficult. But he has certain conditions, which Abby must fulfill. Finding all options bleak, Abby decides to agree to his conditions and travel 33 years back in time, that is, in 1980.\n",
      "Thereafter, a series of unforeseen incidents and intricacies of relationships make Abby’s life in 1980 as eventful as ever. But flung between the two worlds of 1980 and 2013 both in his personal and professional life, Abby represents the predicament of a man struggling to survive in this competitive world.\n",
      "----------------------------------------\n",
      "Título: Dimensions\n",
      "Trama: The film follows Stephen, a brilliant young scientist who lives in Cambridge, England, in what appears to be the 1920s. His world is turned upside down upon meeting a charismatic and inspirational professor at a garden party, who demonstrates to Stephen and his friends what life would be like if they were one-, or two-dimensional beings. He then proceeds to explain that by manipulating other dimensions, time travel may actually be possible.\n",
      "Soon after the professor's visit, Stephan,his cousin, Conrad, and his neighbor, Victoria, were fooling around by a well. Conrad throws Victoria's skipping rope down the well. The nanny catches the boys rolling around fighting and drags them in the house by the ears leaving Victoria alone to play outside by herself. After some time, she decides to climb down the well to get her skipping rope. She never climbs out of the well and her body is never found.\n",
      "As Stephen’s life unfolds, events lead him to dedicate himself to turning the Professor’s theories of time travel into reality. Jealousy, love, obsession, temptation and greed surround him, influencing his fragile mind and the direction of his work.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Consulta para buscar películas relacionadas con \"time travel\"\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"plot\": \"time travel\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ejecutar la consulta\n",
    "response = es.search(index=index_name, body=query, size=5)  # Limitar a 5 resultados\n",
    "print(\"Películas relacionadas con 'time travel':\")\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Título: {hit['_source']['title']}\")\n",
    "    print(f\"Trama: {hit['_source']['plot']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
