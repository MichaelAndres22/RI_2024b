{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2219b455c1e0ef",
   "metadata": {},
   "source": [
    "# Ejercicio 02: Cálculo de la Matriz TF-IDF y Búsqueda de Consultas en un Corpus\n",
    "\n",
    "El objetivo de este ejercicio es calcular la matriz TF-IDF de un corpus de documentos y luego aplicar una serie de consultas para recuperar los documentos más relevantes. Este ejercicio te ayudará a comprender cómo funciona el modelo de espacio vectorial y cómo se utiliza TF-IDF para ponderar términos en documentos y consultas.\n",
    "\n",
    "Seguirás los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1290fb0f5143d",
   "metadata": {},
   "source": [
    "Pasos del Ejercicio\n",
    "\n",
    "1. Preprocesamiento del texto:\n",
    "    * Lectura del corpus desde el archivo TXT.\n",
    "    * Tokenización de los documentos.\n",
    "    * Normalización del texto (conversión a minúsculas, eliminación de signos de puntuación).\n",
    "    * Eliminación de palabras vacías (stopwords).\n",
    "\n",
    "2. Construcción de la matriz TF-IDF:\n",
    "    * Cálculo de la frecuencia de término (TF) para cada término en cada documento.\n",
    "    * Cálculo de la frecuencia inversa de documento (IDF) para cada término en el corpus.\n",
    "    * Cálculo del peso TF-IDF para cada término en cada documento.\n",
    "\n",
    "3. Procesamiento de las consultas:\n",
    "    * Preprocesamiento de las consultas de manera similar a los documentos.\n",
    "    * Representación de las consultas en el espacio vectorial TF-IDF.\n",
    "\n",
    "4. Cálculo de similitudes:\n",
    "    * Cálculo de la similitud entre cada consulta y los documentos del corpus utilizando la similitud del coseno.\n",
    "\n",
    "5. Ranking de documentos:\n",
    "    * Ordenar los documentos de mayor a menor similitud para cada consulta.\n",
    "    * Mostrar los documentos más relevantes para cada consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431356e916e78a3f",
   "metadata": {},
   "source": [
    "Consultas\n",
    "\n",
    "Las consultas a aplicar son las siguientes:\n",
    "\n",
    "    \"inteligencia artificial en medicina\"\n",
    "    \"beneficios de la educación a distancia\"\n",
    "    \"realidad aumentada en videojuegos\"\n",
    "    \"desarrollo personal y hábitos saludables\"\n",
    "    \"futuro del comercio electrónico\"\n",
    "    \"tecnologías en cine moderno\"\n",
    "    \"competencias de e-sports\"\n",
    "    \"diagnóstico con dispositivos portátiles\"\n",
    "    \"literatura de ciencia ficción\"\n",
    "    \"plataformas de streaming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691d0449-cfea-4b0f-b389-b4b1e6c090c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias Necesarias\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d0fc1-adca-48ca-bcc7-2a9783f60629",
   "metadata": {},
   "source": [
    "**1. Preprocesamiento del texto:**\n",
    "\n",
    "Lectura del corpus desde el archivo TXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9e88d-60c8-452e-98d5-d91c8fee6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo TXT con el corpus desde la carpeta Datasets\n",
    "with open('/kaggle/input/02tfidfmatrix-corpus/02tfidfmatrix_corpus.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Imprimir el contenido del corpus\n",
    "print(\"Contenido del corpus:\")\n",
    "for idx, doc in enumerate(corpus):\n",
    "    print(f\"Documento {idx + 1}: {doc.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742f8f8-df9d-470d-ac27-69d8993c8e14",
   "metadata": {},
   "source": [
    "**Tokenización de los documentos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895bf16-d387-4fe1-9f53-360c000f5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(text):\n",
    "    # Usar expresiones regulares para dividir el texto en palabras\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())  # Convertimos a minúsculas y extraemos palabras\n",
    "    return tokens\n",
    "\n",
    "# Aplicar la tokenización a cada documento en el corpus\n",
    "corpus_tokenizado = [tokenizar(doc) for doc in corpus]\n",
    "\n",
    "# Imprimir el corpus tokenizado\n",
    "print(\"Corpus tokenizado:\")\n",
    "for idx, tokens in enumerate(corpus_tokenizado):\n",
    "    print(f\"Documento {idx + 1}: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fa31c-d1df-4f96-9341-e54b2579fe1a",
   "metadata": {},
   "source": [
    "**Normalización del texto (conversión a minúsculas, eliminación de signos de puntuación).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443797c7-4d46-459c-9932-e6e22d57f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar signos de puntuación utilizando expresiones regulares\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Eliminar tildes\n",
    "    # Crear una tabla de traducción para eliminar tildes\n",
    "    tabla = str.maketrans(\n",
    "        \"áéíóúüñ\",  # caracteres originales\n",
    "        \"aeiouun\"   # caracteres reemplazados\n",
    "    )\n",
    "    text = text.translate(tabla)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Aplicar la normalización a cada documento en el corpus\n",
    "corpus_normalizado = [normalizar(doc) for doc in corpus]\n",
    "\n",
    "# Imprimir el corpus normalizado\n",
    "print(\"Corpus normalizado:\")\n",
    "for idx, doc in enumerate(corpus_normalizado):\n",
    "    print(f\"Documento {idx + 1}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06297a86-f264-4ae2-a319-cf3ee9483376",
   "metadata": {
    "tags": []
   },
   "source": [
    "**2. Construcción de la matriz TF-IDF**\n",
    "\n",
    "Cálculo de la frecuencia de término (TF) para cada término en cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa66dd7-d655-44c8-a7d6-c698aaf6e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el vectorizador para calcular la frecuencia de términos\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Aplicar el vectorizador al corpus normalizado para obtener la matriz TF\n",
    "tf_matrix = vectorizer.fit_transform(corpus_normalizado)\n",
    "\n",
    "# Convertir la matriz a un DataFrame para facilitar la visualización\n",
    "tf_df = pd.DataFrame(tf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Imprimir la matriz TF\n",
    "print(\"Matriz TF (Frecuencia de Términos):\")\n",
    "print(tf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6b158-bf24-4ba3-9241-ce57fb77b7bf",
   "metadata": {},
   "source": [
    "**Visualización de terminos en orden de frecuencia, simplemente para comprobar que los terminos que más se repiten dentro del corpus serian las stopword.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43b45a-0d5f-4822-96ff-e4ced03c262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar las frecuencias de cada término en todos los documentos\n",
    "term_frecuencia = tf_df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Convertir a un DataFrame para una mejor visualización\n",
    "term_frecuencia_df = pd.DataFrame(term_frecuencia, columns=['Frecuencia']).reset_index()\n",
    "term_frecuencia_df.columns = ['Término', 'Frecuencia']\n",
    "\n",
    "# Imprimir los términos ordenados por frecuencia\n",
    "print(\"Términos ordenados por frecuencia:\")\n",
    "print(term_frecuencia_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81976a64-477a-4c98-8399-0e3b4c78b8a3",
   "metadata": {},
   "source": [
    "**Cálculo de la frecuencia inversa de documento (IDF) para cada término en el corpus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe0c6d-42a9-4109-b52a-e7734561ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número total de documentos en el corpus\n",
    "N = len(corpus_normalizado)\n",
    "\n",
    "# Calcular el número de documentos en los que aparece cada término\n",
    "doc_frecuencia = (tf_df > 0).sum()\n",
    "\n",
    "# Calcular el IDF usando la fórmula\n",
    "idf_values = np.log(N / doc_frecuencia)\n",
    "\n",
    "# Convertir a un DataFrame para facilitar la visualización\n",
    "idf_df = pd.DataFrame(idf_values, columns=['IDF']).reset_index()\n",
    "idf_df.columns = ['Término', 'IDF']\n",
    "\n",
    "# Imprimir los valores IDF\n",
    "print(\"Frecuencia Inversa de Documento (IDF):\")\n",
    "print(idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d28f5f-d00b-444e-9380-3b6c3a16f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar los valores de IDF de mayor a menor\n",
    "idf_ordenado = idf_df.sort_values(by='IDF', ascending=False)\n",
    "\n",
    "# Imprimir los valores IDF ordenados\n",
    "print(\"Frecuencia Inversa de Documento (IDF) ordenada de mayor a menor:\")\n",
    "print(idf_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be19a2-dfdc-4565-a145-138b589a53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la matriz TF a un arreglo de NumPy para la multiplicación\n",
    "tf_array = tf_df.values\n",
    "\n",
    "# Calcular la matriz TF-IDF multiplicando TF por IDF\n",
    "tfidf_matriz = tf_array * idf_values.values\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame para facilitar la visualización\n",
    "tfidf_df = pd.DataFrame(tfidf_matriz, columns=idf_df['Término'])\n",
    "\n",
    "# Imprimir la matriz TF-IDF\n",
    "print(\"Matriz TF-IDF:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482d7ab-b19f-4538-899a-4eee058d4ed8",
   "metadata": {},
   "source": [
    "**Procedemos a eliminar las stopwords.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee6ddb-500a-4314-b1c3-5f3a4a8a1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    'la', 'las', 'el', 'los', 'de', 'y', 'en', 'a', 'que', 'con', 'por', 'para', 'como', 'más', 'es', 'se', 'esto', 'este', \n",
    "    'esta', 'de', 'un', 'una', 'lo', 'al', 'del', 'su', 'las', 'ser', 'está', 'están', 'o', 'pero', 'no', 'si', 'con', 'su', \n",
    "    'sobre', 'entre', 'este', 'también', 'esos', 'esas', 'esto', 'ese', 'por', 'ademas', 'cuando', 'ya', 'nos', 'tiene', 'nosotros', \n",
    "    'mi', 'tú', 'te', 'su', 'y', 'se', 'un', 'al', 'desde', 'hasta', 'durante', 'aunque', 'al', 'muy', 'hay', 'donde', 'esto', \n",
    "    'ser', 'una', 'los', 'mientras', 'cual', 'quien', 'que', 'sido', 'su', 'sobre', 'esto', 'ella', 'esto', 'yo', 'debería', \n",
    "    'su', 'mi', 'tiempo', 'tal', 'vez', 'tan', 'uno', 'los', 'hace', 'muchos', 'otros', 'estas', 'ellas', 'nosotros', 'ellas', \n",
    "    'algunas', 'algún', 'sólo', 'vez', 'que', 'más', 'del', 'menos', 'todo', 'al', 'siempre', 'por', 'también', 'en', 'todos'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913e817-af9d-4c58-94bb-5b65727d4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las columnas de la matriz TF-IDF para eliminar las stopwords en español\n",
    "columns_to_keep = [term for term in tfidf_df.columns if term not in stopwords]\n",
    "\n",
    "# Crear una nueva matriz TF-IDF sin las stopwords\n",
    "tfidf_filtered_df = tfidf_df[columns_to_keep]\n",
    "\n",
    "# Imprimir la nueva matriz TF-IDF sin stopwords\n",
    "print(\"Matriz TF-IDF sin Stopwords:\")\n",
    "print(tfidf_filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ea87f-3f06-4700-8041-27c84c74ba64",
   "metadata": {},
   "source": [
    "**3. Procesamiento de las consultas:**\n",
    "\n",
    "**Preprocesamiento de las consultas de manera similar a los documentos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcc755-ce29-4563-98a3-937a14782de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"inteligencia artificial en medicina\",\n",
    "    \"beneficios de la educación a distancia\",\n",
    "    \"realidad aumentada en videojuegos\",\n",
    "    \"desarrollo personal y hábitos saludables\",\n",
    "    \"futuro del comercio electrónico\",\n",
    "    \"tecnologías en cine moderno\",\n",
    "    \"competencias de e-sports\",\n",
    "    \"diagnóstico con dispositivos portátiles\",\n",
    "    \"literatura de ciencia ficción\",\n",
    "    \"plataformas de streaming\"\n",
    "]\n",
    "\n",
    "# Aplicar la normalización a cada consulta\n",
    "queries_normalizadas = [normalizar(query) for query in queries]\n",
    "\n",
    "# Imprimir las consultas normalizadas\n",
    "print(\"Consultas normalizadas:\")\n",
    "for idx, query in enumerate(queries_normalizadas):\n",
    "    print(f\"Consulta {idx + 1}: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88dcdfa-398f-4ec9-bdae-14f4196509d2",
   "metadata": {},
   "source": [
    "**Representación de las consultas en el espacio vectorial TF-IDF.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f6819-6df6-4165-bc42-60af629a4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la normalización y tokenización a las consultas\n",
    "queries_normalizadas = [normalizar(query) for query in queries]\n",
    "\n",
    "# Tokenizar las consultas normalizadas\n",
    "queries_tokenizadas = [tokenizar(query) for query in queries_normalizadas]\n",
    "\n",
    "# Eliminar las stopwords de las consultas\n",
    "queries_sin_stopwords = []\n",
    "for query in queries_tokenizadas:\n",
    "    query_sin_stopwords = [word for word in query if word not in stopwords]\n",
    "    queries_sin_stopwords.append(query_sin_stopwords)\n",
    "\n",
    "# Reconvertir las consultas sin stopwords a texto (para pasarlas al vectorizador)\n",
    "queries_limpias = [' '.join(query) for query in queries_sin_stopwords]\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# Convertir la matriz a un DataFrame para facilitar la visualización\n",
    "queries_tfidf_matrix = vectorizer_tfidf.fit_transform(queries_limpias)\n",
    "queries_tfidf_df = pd.DataFrame(queries_tfidf_matrix.toarray(), columns=vectorizer_tfidf.get_feature_names_out())\n",
    "\n",
    "# Imprimir la matriz TF-IDF de las consultas\n",
    "print(\"Matriz TF-IDF para las consultas:\")\n",
    "print(queries_tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43d8bf-27fb-44a6-b0c6-8cff763b1379",
   "metadata": {},
   "source": [
    "**4. Cálculo de similitudes:**\n",
    "\n",
    "Cálculo de la similitud entre cada consulta y los documentos del corpus utilizando la similitud del coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a170ef8-c0f7-46fa-b02d-ae780002cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el vectorizador TF-IDF para los documentos\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words=stopwords)  # Usamos el mismo vectorizador para consultas y documentos\n",
    "\n",
    "# Se convierte el corpus de documentos en su representación TF-IDF\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(corpus)\n",
    "\n",
    "# Transformar las consultas con el mismo vectorizador\n",
    "queries_tfidf_matrix = vectorizer_tfidf.transform(queries_limpias)\n",
    "\n",
    "# Calcular la similitud del coseno entre las consultas y los documentos\n",
    "similitudes_consultas_documentos = cosine_similarity(queries_tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Convertir la matriz de similitudes a un DataFrame para mejor visualización\n",
    "similitudes_df = pd.DataFrame(similitudes_consultas_documentos,\n",
    "                              columns=[f'Documento {i+1}' for i in range(len(corpus))],\n",
    "                              index=[f'Consulta {i+1}' for i in range(len(queries))])\n",
    "\n",
    "# Imprimir la matriz de similitudes entre consultas y documentos\n",
    "print(\"Matriz de Similitud del Coseno entre consultas y documentos:\")\n",
    "print(similitudes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903cad5-935b-4e1c-b475-20d0a74e3c2f",
   "metadata": {},
   "source": [
    "**5. Ranking de documentos:**\n",
    "\n",
    "Ordenar los documentos de mayor a menor similitud para cada consulta y mostrar los documentos más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e6f4a-2365-420e-b3f0-058c4417fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for consulta_idx, consulta in similitudes_df.iterrows():\n",
    "    consulta_idx_int = int(re.search(r'\\d+', consulta_idx).group())  # Extrae el número de la consulta\n",
    "    \n",
    "    consulta_texto = queries[consulta_idx_int - 1]  # Obtener el texto original de la consulta\n",
    "    \n",
    "    # Imprimir el ranking de documentos para cada consulta\n",
    "    print(f\"\\nRanking de documentos para la Consulta {consulta_idx_int} - ({consulta_texto}):\")\n",
    "    \n",
    "    ranking_documentos = consulta.sort_values(ascending=False)  # Ordenamos de mayor a menor\n",
    "    \n",
    "    # Mostrar los documentos más relevantes\n",
    "    top_documentos = ranking_documentos.head(3)  # Los 3 más relevantes\n",
    "    for doc_idx, score in top_documentos.items():\n",
    "        # Mostrar el documento y su similitud con el formato deseado\n",
    "        print(f\"**//** {doc_idx}   Similitud Coseno = {score:.6f} **//**\")\n",
    "        \n",
    "        # Mostrar el texto del documento correspondiente\n",
    "        doc_texto = corpus[int(doc_idx.split()[-1]) - 1].strip()  # Obtener el texto del documento\n",
    "        print(f\"{doc_texto}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
